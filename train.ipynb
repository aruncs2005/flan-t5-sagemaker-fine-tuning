{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine Tune Flan T5 on prompt dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install -U sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install transformers"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset creation\n",
    "\n",
    "We will use the HC3 dataset to fine tune the model. The dataset can be found here on Huggingface - https://huggingface.co/datasets/Hello-SimpleAI/HC3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "  \n",
    "# Opening JSON file\n",
    "f1 = open('data/all.jsonl')\n",
    "Lines1 = f1.readlines()\n",
    "\n",
    "questions, answers = [], []\n",
    "for line in Lines1[:20000]:\n",
    "    row = json.loads(line)\n",
    "    for answer in row[\"human_answers\"]:\n",
    "        questions.append(\"Prompt: \"+row[\"question\"])\n",
    "        answers.append(\"Response: \"+answer)\n",
    "    for answer in row[\"chatgpt_answers\"]:\n",
    "        questions.append(\"Prompt: \"+row[\"question\"])\n",
    "        answers.append(\"Response: \"+answer)\n",
    "\n",
    "test_file = open(\"data/test.jsonl\",\"w\")\n",
    "for line in Lines1[20000:]:\n",
    "    test_file.write(line)\n",
    "\n",
    "test_file.close()\n",
    "\n",
    "\n",
    "df = pd.DataFrame()\n",
    "df[\"question\"] = questions\n",
    "df[\"answer\"] = answers\n",
    "df = df.sample(frac = 1)\n",
    "df_train = df.iloc[:60000,:]\n",
    "df_val = df.iloc[60000:,:]\n",
    "\n",
    "df_train.to_csv(\"data/train.csv\", index=False)\n",
    "df_val.to_csv(\"data/val.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload data to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker.pytorch import PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = sagemaker.Session()\n",
    "# sagemaker session bucket -> used for uploading data, models and logs\n",
    "# sagemaker will automatically create this bucket if it not exists\n",
    "sagemaker_session_bucket=None\n",
    "if sagemaker_session_bucket is None and sess is not None:\n",
    "    # set to default bucket if a bucket name is not given\n",
    "    sagemaker_session_bucket = sess.default_bucket()\n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "sess = sagemaker.Session(default_bucket=sagemaker_session_bucket)\n",
    "\n",
    "print(f\"sagemaker role arn: {role}\")\n",
    "print(f\"sagemaker bucket: {sess.default_bucket()}\")\n",
    "print(f\"sagemaker session region: {sess.boto_region_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_url = sess.upload_data(\n",
    "    path=\"data/train.csv\",\n",
    "    key_prefix=\"promptsds\",\n",
    ")\n",
    "\n",
    "valid_data_url = sess.upload_data(\n",
    "    path=\"data/val.csv\",\n",
    "    key_prefix=\"promptsds\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"training file path {train_data_url}\")\n",
    "print(f\"validation file path {valid_data_url}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine Tune FLAN T5 XXL (11b) on Seq2Seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_job_name=\"finetune-flant5-11b\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {}\n",
    "\n",
    "hyperparameters[\"model_name_or_path\"] = \"google/flan-t5-xxl\"\n",
    "hyperparameters[\"train_file\"] = \"/opt/ml/input/data/train/train.csv\"\n",
    "hyperparameters[\"validation_file\"] = \"/opt/ml/input/data/valid/val.csv\"\n",
    "hyperparameters[\"per_device_train_batch_size\"] = 8\n",
    "hyperparameters[\"per_device_eval_batch_size\"] = 8\n",
    "hyperparameters[\"block_size\"] = 2048\n",
    "hyperparameters[\"checkpoint_dir\"] = \"/opt/ml/checkpoints\"\n",
    "hyperparameters[\"num_train_epochs\"] = 1\n",
    "hyperparameters[\"max_train_steps\"] = 250"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Store model files as checkpoints for easy deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "checkpoint_dir = \"/opt/ml/checkpoints\"\n",
    "checkpoint_s3_path = \"s3://\" + sess.default_bucket() + \"/flant5-checkpoints\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smp_options = {\n",
    "    \"enabled\":True,\n",
    "    \"parameters\": {                        # Required\n",
    "        \"pipeline_parallel_degree\": 1,     # Required\n",
    "        \"ddp\": True,\n",
    "        # parameters for sharded data parallelism\n",
    "        \"sharded_data_parallel_degree\": 16,              # Add this to activate sharded data parallelism\n",
    "        \"partitions\":1,\n",
    "        \"bf16\":True,\n",
    "        \"skip_tracing\": True\n",
    "    }\n",
    "}\n",
    "\n",
    "mpi_options = {\n",
    "    \"enabled\" : True,                      # Required\n",
    "    \"processes_per_host\" : 8               # Required\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# launch with smp\n",
    "\n",
    "estimator = PyTorch(\n",
    "    base_job_name=base_job_name,\n",
    "    source_dir=\"./scripts\",\n",
    "    entry_point=\"train.py\",\n",
    "    role=role,\n",
    "    framework_version=\"1.13.1\",\n",
    "    py_version=\"py39\", \n",
    "    instance_count=2,\n",
    "    instance_type=\"ml.p4d.24xlarge\",\n",
    "    hyperparameters=hyperparameters,\n",
    "    checkpoint_local_path=checkpoint_dir,   \n",
    "    checkpoint_s3_uri=checkpoint_s3_path,\n",
    "    disable_profiler=True,\n",
    "    keep_alive_period_in_seconds=600,\n",
    "    debugger_hook_config=False,\n",
    "    distribution={\n",
    "        \"smdistributed\": {\"modelparallel\": smp_options},\n",
    "        \"mpi\": mpi_options\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.fit({\"train\":train_data_url,\"valid\":valid_data_url})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Store the checkpoint path to reuse in the deploy notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store checkpoint_s3_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "arunpy39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2df149412efc1526e813459d121195dcad0cc0c344007149632d30b7359a266e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
